# Gu√≠a de Configuraci√≥n de Supabase para CompraAgil_VB

## üìã Resumen

Esta gu√≠a te ayudar√° a configurar correctamente Supabase para el proyecto de scraping y matching de Compras √Ågiles de MercadoP√∫blico.

## üîë Paso 1: Obtener Credenciales de Supabase

### 1.1 Acceder a tu Proyecto

1. Ve a [supabase.com/dashboard](https://supabase.com/dashboard)
2. Inicia sesi√≥n con tu cuenta
3. Selecciona tu proyecto (o crea uno nuevo si no tienes)

### 1.2 Obtener las API Keys

1. En el dashboard de tu proyecto, ve a **Settings** (‚öôÔ∏è √≠cono de configuraci√≥n en la barra lateral)
2. Selecciona **API** en el men√∫ de configuraci√≥n
3. Encontrar√°s dos secciones importantes:

#### Project URL
```
https://[tu-proyecto-id].supabase.co
```

#### API Keys
- **`anon` / `public`**: Esta key es segura para uso en el cliente
- **`service_role` / `secret`**: Esta key tiene acceso total (‚ö†Ô∏è NUNCA la expongas p√∫blicamente)

**Para este proyecto, usaremos la `service_role` key** porque nuestro scraper necesita permisos completos de escritura.

## üóÑÔ∏è Paso 2: Crear las Tablas en Supabase

### 2.1 Acceder al SQL Editor

1. En tu dashboard de Supabase, ve a **SQL Editor** en la barra lateral
2. Click en **+ New query**
3. Copia y pega el siguiente SQL:

```sql
-- ============================================
-- TABLAS PARA SISTEMA DE COMPRAS √ÅGILES
-- ============================================

-- TABLA PRINCIPAL: Licitaciones/Compras √Ågiles
CREATE TABLE IF NOT EXISTS licitaciones (
  codigo TEXT PRIMARY KEY,
  titulo TEXT,
  organismo TEXT,
  departamento TEXT,
  presupuesto_estimado NUMERIC(12,2),
  fecha_publicacion TIMESTAMP,
  fecha_cierre_primer_llamado TIMESTAMP,
  fecha_cierre_segundo_llamado TIMESTAMP,
  direccion_entrega TEXT,
  plazo_entrega TEXT,
  tipo_presupuesto TEXT,
  estado TEXT,
  estado_detallado TEXT,
  link_detalle TEXT,
  rut_institucion TEXT,
  tiene_adjuntos BOOLEAN DEFAULT FALSE,
  
  -- METADATA PARA PROCESAMIENTO
  fecha_extraccion TIMESTAMP DEFAULT NOW(),
  procesada BOOLEAN DEFAULT FALSE,
  match_encontrado BOOLEAN DEFAULT FALSE,
  oferta_enviada BOOLEAN DEFAULT FALSE,
  oferta_id TEXT,
  
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- TABLA: Productos/Items de cada Licitaci√≥n
CREATE TABLE IF NOT EXISTS licitacion_items (
  id SERIAL PRIMARY KEY,
  licitacion_codigo TEXT NOT NULL REFERENCES licitaciones(codigo) ON DELETE CASCADE,
  item_index INTEGER NOT NULL,
  
  -- DATOS DE MERCADOP√öBLICO
  producto_id TEXT,
  nombre TEXT,
  descripcion TEXT,
  cantidad TEXT,
  unidad TEXT,
  
  -- MATCHING CON INVENTARIO
  id_producto_inventario TEXT,
  match_confidence NUMERIC(5,2),
  precio_unitario_sugerido NUMERIC(12,2),
  precio_total_sugerido NUMERIC(12,2),
  margen_estimado NUMERIC(5,2),
  
  -- METADATA
  match_procesado BOOLEAN DEFAULT FALSE,
  incluido_en_oferta BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMP DEFAULT NOW(),
  
  UNIQUE(licitacion_codigo, item_index)
);

-- TABLA: Documentos adjuntos (opcional)
CREATE TABLE IF NOT EXISTS licitacion_documentos (
  id SERIAL PRIMARY KEY,
  licitacion_codigo TEXT NOT NULL REFERENCES licitaciones(codigo) ON DELETE CASCADE,
  nombre TEXT,
  url TEXT,
  created_at TIMESTAMP DEFAULT NOW(),
  
  UNIQUE(licitacion_codigo, url)
);

-- ============================================
-- √çNDICES PARA OPTIMIZAR CONSULTAS
-- ============================================

CREATE INDEX IF NOT EXISTS idx_licitaciones_fecha_pub 
  ON licitaciones(fecha_publicacion DESC);

CREATE INDEX IF NOT EXISTS idx_licitaciones_no_procesada 
  ON licitaciones(procesada) 
  WHERE procesada = FALSE;

CREATE INDEX IF NOT EXISTS idx_licitaciones_match 
  ON licitaciones(match_encontrado) 
  WHERE match_encontrado = TRUE;

CREATE INDEX IF NOT EXISTS idx_items_licitacion 
  ON licitacion_items(licitacion_codigo);

CREATE INDEX IF NOT EXISTS idx_items_no_procesado 
  ON licitacion_items(match_procesado) 
  WHERE match_procesado = FALSE;

CREATE INDEX IF NOT EXISTS idx_licitaciones_fecha_extraccion 
  ON licitaciones(fecha_extraccion DESC);

-- ============================================
-- TRIGGER PARA UPDATED_AT AUTOM√ÅTICO
-- ============================================

CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
   NEW.updated_at = NOW();
   RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_licitaciones_updated_at 
  BEFORE UPDATE ON licitaciones
  FOR EACH ROW 
  EXECUTE PROCEDURE update_updated_at_column();

-- ============================================
-- VISTA: Licitaciones con conteo de items
-- ============================================

CREATE OR REPLACE VIEW v_licitaciones_resumen AS
SELECT 
  l.*,
  COUNT(li.id) as cantidad_items,
  COUNT(CASE WHEN li.match_procesado = TRUE THEN 1 END) as items_con_match
FROM licitaciones l
LEFT JOIN licitacion_items li ON l.codigo = li.licitacion_codigo
GROUP BY l.codigo;

-- ============================================
-- POL√çTICAS RLS (Row Level Security)
-- ============================================
-- Por ahora deshabilitado para simplificar desarrollo
-- Habilitar en producci√≥n:

-- ALTER TABLE licitaciones ENABLE ROW LEVEL SECURITY;
-- ALTER TABLE licitacion_items ENABLE ROW LEVEL SECURITY;
-- ALTER TABLE licitacion_documentos ENABLE ROW LEVEL SECURITY;

-- ============================================
-- VERIFICACI√ìN
-- ============================================

SELECT 'Tablas creadas exitosamente' as mensaje;
```

4. Click en **Run** (‚ñ∂Ô∏è) para ejecutar el script
5. Deber√≠as ver el mensaje: `Tablas creadas exitosamente`

### 2.2 Verificar las Tablas

Ejecuta esta query para verificar:

```sql
SELECT 
  table_name,
  column_name,
  data_type
FROM information_schema.columns
WHERE table_schema = 'public'
  AND table_name IN ('licitaciones', 'licitacion_items', 'licitacion_documentos')
ORDER BY table_name, ordinal_position;
```

## üîß Paso 3: Configuraci√≥n Local

### 3.1 Crear archivo .env

En tu proyecto local, crea el archivo `.env` en la carpeta `mercadopublico-scraper/`:

```bash
cd ~/CompraAgil_VB/mercadopublico-scraper
cp .env.example .env
nano .env
```

### 3.2 Configurar las variables

Edita el archivo `.env` con tus credenciales:

```bash
SUPABASE_URL=https://[tu-proyecto-id].supabase.co
SUPABASE_KEY=[tu-service-role-key]

# Configuraci√≥n de scraping
MAX_PAGES=5
INCREMENTAL_MODE=true
```

‚ö†Ô∏è **IMPORTANTE**: 
- Reemplaza `[tu-proyecto-id]` con el ID real de tu proyecto
- Reemplaza `[tu-service-role-key]` con tu key de Supabase
- **NUNCA** subas el archivo `.env` a GitHub (ya est√° en `.gitignore`)

### 3.3 Probar la conexi√≥n localmente

```bash
cd ~/CompraAgil_VB/mercadopublico-scraper
npm install
node scraper.js --test
```

Si todo est√° bien configurado, deber√≠as ver:
```
Iniciando scraper de Compras √Ågiles...
P√°gina 1/1: https://buscador.mercadopublico.cl/compra-agil?...
Total resultados detectado: XXXX
Extra√≠das X compras en la p√°gina 1
Upsert OK: X filas en 'licitaciones'.
Finalizado. Compras √∫nicas vistas (memoria): X
```

## üöÄ Paso 4: Configuraci√≥n en GitHub Actions

### 4.1 Configurar GitHub Secrets

1. Ve a tu repositorio: [github.com/evarasvb/CompraAgil_VB](https://github.com/evarasvb/CompraAgil_VB)
2. Click en **Settings** (‚öôÔ∏è)
3. En el men√∫ lateral, ve a **Secrets and variables** ‚Üí **Actions**
4. Click en **New repository secret**
5. Crea estos dos secrets:

#### Secret 1: SUPABASE_URL
- **Name**: `SUPABASE_URL`
- **Secret**: `https://[tu-proyecto-id].supabase.co`

#### Secret 2: SUPABASE_KEY
- **Name**: `SUPABASE_KEY`
- **Secret**: `[tu-service-role-key]`

### 4.2 Verificar los Secrets

Despu√©s de crearlos, deber√≠as ver:
- ‚úÖ SUPABASE_URL
- ‚úÖ SUPABASE_KEY

### 4.3 Ejecutar el Workflow Manualmente

1. Ve a la pesta√±a **Actions** en tu repositorio
2. Selecciona el workflow **Scraper Compras √Ågiles (Cada Hora)**
3. Click en **Run workflow**
4. Espera a que termine (deber√≠a tomar 2-5 minutos)
5. Revisa los logs para confirmar que funciona

## üìä Paso 5: Verificar los Datos en Supabase

### 5.1 Ver datos en Table Editor

1. En Supabase, ve a **Table Editor**
2. Selecciona la tabla `licitaciones`
3. Deber√≠as ver las compras extra√≠das
4. Revisa tambi√©n `licitacion_items` para ver los productos

### 5.2 Queries √∫tiles

#### Ver √∫ltimas compras extra√≠das
```sql
SELECT 
  codigo,
  titulo,
  organismo,
  presupuesto_estimado,
  fecha_publicacion,
  fecha_extraccion
FROM licitaciones
ORDER BY fecha_extraccion DESC
LIMIT 20;
```

#### Ver compras con sus items
```sql
SELECT 
  l.codigo,
  l.titulo,
  l.presupuesto_estimado,
  li.item_index,
  li.nombre as item_nombre,
  li.cantidad,
  li.unidad
FROM licitaciones l
JOIN licitacion_items li ON l.codigo = li.licitacion_codigo
WHERE l.procesada = FALSE
ORDER BY l.fecha_publicacion DESC, li.item_index;
```

#### Estad√≠sticas generales
```sql
SELECT 
  COUNT(*) as total_licitaciones,
  COUNT(CASE WHEN procesada = FALSE THEN 1 END) as pendientes_procesar,
  COUNT(CASE WHEN match_encontrado = TRUE THEN 1 END) as con_match,
  COUNT(CASE WHEN oferta_enviada = TRUE THEN 1 END) as ofertas_enviadas,
  MAX(fecha_extraccion) as ultima_extraccion
FROM licitaciones;
```

## üîç Soluci√≥n de Problemas

### Error: "Invalid API key"

‚úÖ **Soluci√≥n**:
1. Verifica que est√°s usando la **service_role key** (no la anon key)
2. Confirma que la key no tiene espacios al inicio/final
3. Regenera la key en Supabase si es necesario (Settings ‚Üí API ‚Üí Generate new secret)

### Error: "relation 'licitaciones' does not exist"

‚úÖ **Soluci√≥n**:
1. Ejecuta nuevamente el script SQL del Paso 2.1
2. Verifica que est√°s en el schema correcto (`public`)
3. Confirma que tu SUPABASE_URL apunta al proyecto correcto

### GitHub Action falla con timeout

‚úÖ **Soluci√≥n**:
1. Reduce `MAX_PAGES` en el workflow (ej: de 5 a 2)
2. Aumenta el timeout en `scraper.js` (config.navigationTimeoutMs)
3. Verifica que Chrome/Puppeteer se instala correctamente

### No se extraen productos

‚úÖ **Soluci√≥n**:
1. Verifica que la funci√≥n `scrapeCompraDetallada` est√° funcionando
2. Prueba localmente con `--test` y `--headed` para ver el navegador
3. Revisa los selectores CSS en el c√≥digo (pueden cambiar si MercadoP√∫blico actualiza su sitio)

## üìà Pr√≥ximos Pasos

### Fase 2: Matching Engine (n8n)
- Configurar workflow de matching autom√°tico
- Conectar con tu inventario (Google Sheets/Excel)
- Calcular precios y m√°rgenes

### Fase 3: Integraci√≥n Odoo
- Crear oportunidades autom√°ticas en CRM
- Sincronizar productos matched

### Fase 4: Dashboard Lovable
- Visualizar licitaciones en tiempo real
- Monitorear performance de matching
- Panel de control de ofertas

## üÜò Soporte

Si tienes problemas:
1. Revisa los logs del scraper
2. Verifica las credenciales de Supabase
3. Consulta la documentaci√≥n de [Supabase](https://supabase.com/docs)
4. Revisa el c√≥digo en el repositorio

---

**√öltima actualizaci√≥n**: 2026-01-09  
**Versi√≥n**: 1.0.0
